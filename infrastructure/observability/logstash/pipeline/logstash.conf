input {
  # Beats input for structured logs
  beats {
    port => 5044
  }
  
  # TCP input for JSON logs
  tcp {
    port => 5000
    codec => json
  }
  
  # HTTP input for application logs
  http {
    port => 8080
    codec => json
  }
}

filter {
  # Parse JSON if not already parsed
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
    }
  }
  
  # Add timestamp if not present
  if ![timestamp] {
    mutate {
      add_field => { "timestamp" => "%{@timestamp}" }
    }
  }
  
  # Parse log level
  if [level] {
    mutate {
      uppercase => [ "level" ]
    }
  }
  
  # Add environment tag
  mutate {
    add_field => { "environment" => "${ENVIRONMENT:development}" }
  }
  
  # Grok pattern for unstructured logs
  if [message] !~ /^\{.*\}$/ {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:level}\] \[%{DATA:service}\] %{GREEDYDATA:log_message}" }
    }
  }
  
  # Parse trace context
  if [trace_id] {
    mutate {
      add_field => { "has_trace" => "true" }
    }
  }
  
  # Add service tags
  if [service] == "ml-prediction-service" {
    mutate {
      add_tag => [ "ml", "prediction" ]
    }
  }
  
  if [service] == "feature-store" {
    mutate {
      add_tag => [ "data", "features" ]
    }
  }
  
  if [service] == "data-ingestion" {
    mutate {
      add_tag => [ "data", "ingestion" ]
    }
  }
  
  # Drop debug logs in production
  if [environment] == "production" and [level] == "DEBUG" {
    drop { }
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logstash-%{[service]}-%{+YYYY.MM.dd}"
    document_type => "_doc"
  }
  
  # Debug output (only in development)
  if [environment] == "development" {
    stdout {
      codec => rubydebug
    }
  }
}
